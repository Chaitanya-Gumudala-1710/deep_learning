{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CMKiEMEYd8tiPuvvflPUZZAu-vBb-npA",
      "authorship_tag": "ABX9TyMTNH21eidh1iXtfCXHoq7i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitanya-Gumudala-1710/deep_learning/blob/main/neural_network_scratch_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "znj7Ol3jZL5v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/deep-learning/Datasets/insurance_data.csv')"
      ],
      "metadata": {
        "id": "5o5t8BRfirkb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[['age', 'affordibility']], data.bought_insurance, test_size=0.2)"
      ],
      "metadata": {
        "id": "J-gBtFSxjOhy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled['age'] = X_test_scaled['age'] / 100"
      ],
      "metadata": {
        "id": "-LR9T4e-jtq5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(1, input_shape=(2, ), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
        "])"
      ],
      "metadata": {
        "id": "l_8J73gpkEnV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VJM8EBVRllNx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc1B-LqSlw_r",
        "outputId": "ee7612cb-9bd2-4160-a13a-a9a22128d6e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8001 - accuracy: 0.4091\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7996 - accuracy: 0.4091\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7991 - accuracy: 0.4091\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7985 - accuracy: 0.4091\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7980 - accuracy: 0.4091\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7975 - accuracy: 0.4091\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7969 - accuracy: 0.4091\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7964 - accuracy: 0.4091\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7959 - accuracy: 0.4091\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7954 - accuracy: 0.4091\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7948 - accuracy: 0.4091\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7943 - accuracy: 0.4091\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7938 - accuracy: 0.4091\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7933 - accuracy: 0.4091\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7927 - accuracy: 0.4091\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7922 - accuracy: 0.4091\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7917 - accuracy: 0.4091\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7912 - accuracy: 0.4091\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7907 - accuracy: 0.4091\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7902 - accuracy: 0.4091\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7896 - accuracy: 0.4091\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7891 - accuracy: 0.4091\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7886 - accuracy: 0.4091\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7881 - accuracy: 0.4091\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7876 - accuracy: 0.4091\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7871 - accuracy: 0.4091\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7866 - accuracy: 0.4091\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7861 - accuracy: 0.4091\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7856 - accuracy: 0.4091\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7850 - accuracy: 0.4091\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7845 - accuracy: 0.4091\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7840 - accuracy: 0.4091\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7835 - accuracy: 0.4091\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7830 - accuracy: 0.4091\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7825 - accuracy: 0.4091\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7820 - accuracy: 0.4091\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7815 - accuracy: 0.4091\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7810 - accuracy: 0.4091\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7805 - accuracy: 0.4091\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7800 - accuracy: 0.4091\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7795 - accuracy: 0.4091\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7791 - accuracy: 0.4091\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7786 - accuracy: 0.4091\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7781 - accuracy: 0.4091\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7776 - accuracy: 0.4091\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7771 - accuracy: 0.4091\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7766 - accuracy: 0.4091\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7761 - accuracy: 0.4091\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7756 - accuracy: 0.4091\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7751 - accuracy: 0.4091\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7747 - accuracy: 0.4091\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7742 - accuracy: 0.4091\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7737 - accuracy: 0.4091\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7732 - accuracy: 0.4091\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7727 - accuracy: 0.4091\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7722 - accuracy: 0.4091\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7718 - accuracy: 0.4091\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7713 - accuracy: 0.4091\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7708 - accuracy: 0.4091\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7703 - accuracy: 0.4091\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7699 - accuracy: 0.4091\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7694 - accuracy: 0.4091\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7689 - accuracy: 0.4091\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7685 - accuracy: 0.4091\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7680 - accuracy: 0.4091\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7675 - accuracy: 0.4091\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.7671 - accuracy: 0.4091\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7666 - accuracy: 0.4091\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7661 - accuracy: 0.4091\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7657 - accuracy: 0.4091\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7652 - accuracy: 0.4091\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7647 - accuracy: 0.4091\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7643 - accuracy: 0.4091\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7638 - accuracy: 0.4091\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7634 - accuracy: 0.4091\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7629 - accuracy: 0.4091\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7624 - accuracy: 0.4091\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7620 - accuracy: 0.4091\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7615 - accuracy: 0.4091\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7611 - accuracy: 0.4091\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7606 - accuracy: 0.4091\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7602 - accuracy: 0.4091\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7597 - accuracy: 0.4091\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7593 - accuracy: 0.4091\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7588 - accuracy: 0.4091\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7584 - accuracy: 0.4091\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7579 - accuracy: 0.4091\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7575 - accuracy: 0.4091\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7570 - accuracy: 0.4091\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7566 - accuracy: 0.4091\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7562 - accuracy: 0.4091\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7557 - accuracy: 0.4091\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7553 - accuracy: 0.4091\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7548 - accuracy: 0.4091\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7544 - accuracy: 0.4091\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7540 - accuracy: 0.4091\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7535 - accuracy: 0.4091\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.7531 - accuracy: 0.4091\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7527 - accuracy: 0.4091\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7522 - accuracy: 0.4091\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8d6e0fdba0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ_azvbYmO2o",
        "outputId": "0e88b609-e7d1-40ce-8bf1-2263f91bc6da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 834ms/step - loss: 0.4204 - accuracy: 0.8333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42040112614631653, 0.8333333134651184]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w40LqH50mIhC",
        "outputId": "f27c3fd7-7ccd-438c-f23d-3a07c27cb4fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 351ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79510385],\n",
              "       [0.7965717 ],\n",
              "       [0.7876467 ],\n",
              "       [0.7317735 ],\n",
              "       [0.77687716],\n",
              "       [0.772144  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients, intercept = model.get_weights()\n",
        "print(\"Weights :\", coefficients)\n",
        "print(\"Bias :\", intercept)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4WEyR8rmq-6",
        "outputId": "1816a602-9139-4f9d-fe59-791019f9a9ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights : [[0.9034098 ]\n",
            " [0.90274024]]\n",
            "Bias : [-0.097851]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(X):\n",
        "  return 1 / (1 + np.exp(-X))"
      ],
      "metadata": {
        "id": "YHbm2mgagmOZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_predicted):\n",
        "  epsilon = 1e-15\n",
        "  y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
        "  y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
        "  y_predicted_new = np.array(y_predicted_new)\n",
        "  return -np.mean(y_true * np.log(y_predicted_new)+(1 - y_true)*np.log(1 - y_predicted_new))"
      ],
      "metadata": {
        "id": "kP2hWSE6olQ5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.w1 = 1\n",
        "        self.w2 = 1\n",
        "        self.bias = 0\n",
        "    def fit(self, X, y, epochs, loss_threshold):\n",
        "        self.w1, self.w2, self.bias = self.gradient_descent(X.age, X.affordibility, y, epochs, loss_threshold)\n",
        "        print(f\"Final Weights: w1={self.w1}, w2={self.w2}, Bias: {self.bias}\")\n",
        "    def predict(self, X_test):\n",
        "        weighted_sum = self.w1 * X_test.age + self.w2 * X_test.affordibility + self.bias\n",
        "        return sigmoid(weighted_sum)\n",
        "    def gradient_descent(self, X1, X2, y_true, epochs, loss_threshold):\n",
        "        w1 = 1\n",
        "        w2 = 1\n",
        "        bias = 0\n",
        "        rate = 0.5\n",
        "        n = len(X1)\n",
        "        for i in range(epochs):\n",
        "            weighted_sum = w1 * X1 + w2 * X2 + bias\n",
        "            y_predicted = sigmoid(weighted_sum)\n",
        "            loss = log_loss(y_true, y_predicted)\n",
        "            w1d = (1/n) * np.dot(np.transpose(X1), (y_predicted - y_true))\n",
        "            w2d = (1/n) * np.dot(np.transpose(X2), (y_predicted - y_true))\n",
        "            bias_d = np.mean(y_predicted - y_true)\n",
        "            w1 = w1 - rate * w1d\n",
        "            w2 = w2 - rate * w2d\n",
        "            bias = bias - rate * bias_d\n",
        "            print(f\"Epochs: {i}, Weights: w1={w1}, w2={w2}, Bias: {bias}, Loss: {loss}\")\n",
        "        return w1, w2, bias"
      ],
      "metadata": {
        "id": "LCI1swlSdRnU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scratch_network = NeuralNetwork()\n",
        "scratch_network.fit(X_train_scaled, y_train, epochs=100, loss_threshold=0.3644)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MITBpUJxq1fW",
        "outputId": "499cafce-d55c-42c4-aa16-ae3bf13f2e15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0, Weights: w1=0.9628115180166987, w2=0.9229910740487224, Bias: -0.15160837170501573, Loss: 0.800112118992163\n",
            "Epochs: 1, Weights: w1=0.9331982486854798, w2=0.8582772241442965, Bias: -0.28270016700802736, Loss: 0.7437818237736962\n",
            "Epochs: 2, Weights: w1=0.9106229176509149, w2=0.8053402749976748, Bias: -0.39484124595362485, Loss: 0.7026953036352022\n",
            "Epochs: 3, Weights: w1=0.8943317704236683, w2=0.7631378264915681, Bias: -0.49013603371414893, Loss: 0.6734978514488336\n",
            "Epochs: 4, Weights: w1=0.8834801600429366, w2=0.7303474697223078, Bias: -0.5708939689154979, Loss: 0.6531036285806118\n",
            "Epochs: 5, Weights: w1=0.8772305810020495, w2=0.7055749443985231, Bias: -0.6393761048637949, Loss: 0.6389737074947915\n",
            "Epochs: 6, Weights: w1=0.8748127028374031, w2=0.6874920621905456, Bias: -0.6976444712373799, Loss: 0.629175908437134\n",
            "Epochs: 7, Weights: w1=0.8755510567627997, w2=0.6749088526370937, Bias: -0.7474962371293526, Loss: 0.6223166426239217\n",
            "Epochs: 8, Weights: w1=0.8788712189475717, w2=0.666799365605076, Bias: -0.7904529323489717, Loss: 0.6174263808912397\n",
            "Epochs: 9, Weights: w1=0.8842941440323013, w2=0.6623003753517284, Bias: -0.8277792126753559, Loss: 0.6138463707245263\n",
            "Epochs: 10, Weights: w1=0.8914252248910947, w2=0.6606967873392092, Bias: -0.8605141775900509, Loss: 0.6111357260568074\n",
            "Epochs: 11, Weights: w1=0.899941893204195, w2=0.6614020932200046, Bias: -0.8895055833547394, Loss: 0.6090021188751418\n",
            "Epochs: 12, Weights: w1=0.9095816960205553, w2=0.6639383272795106, Bias: -0.9154421754607387, Loss: 0.6072527877445243\n",
            "Epochs: 13, Weights: w1=0.9201316769044645, w2=0.6679176077664879, Bias: -0.9388821876231114, Loss: 0.6057609988318724\n",
            "Epochs: 14, Weights: w1=0.9314193020112412, w2=0.6730260425377225, Bias: -0.9602775271844851, Loss: 0.6044435257824724\n",
            "Epochs: 15, Weights: w1=0.9433048883518089, w2=0.6790101201922221, Bias: -0.979993857328646, Loss: 0.6032457045139247\n",
            "Epochs: 16, Weights: w1=0.9556753736615363, w2=0.6856654087420554, Bias: -0.9983270601270624, Loss: 0.6021315843617588\n",
            "Epochs: 17, Weights: w1=0.9684392328833417, w2=0.692827272025906, Bias: -1.0155166314560125, Loss: 0.601077464256544\n",
            "Epochs: 18, Weights: w1=0.9815223507388118, w2=0.700363293803251, Bias: -1.031756532236794, Loss: 0.6000676601905577\n",
            "Epochs: 19, Weights: w1=0.9948646801729107, w2=0.708167120109769, Bias: -1.047203957759346, Loss: 0.5990917369607849\n",
            "Epochs: 20, Weights: w1=1.0084175413421097, w2=0.7161534663721671, Bias: -1.0619864156599874, Loss: 0.5981426984593798\n",
            "Epochs: 21, Weights: w1=1.022141440130529, w2=0.7242540746680969, Bias: -1.0762074356420495, Loss: 0.5972158046473997\n",
            "Epochs: 22, Weights: w1=1.0360043068643847, w2=0.7324144429343006, Bias: -1.089951174837469, Loss: 0.5963077980177922\n",
            "Epochs: 23, Weights: w1=1.0499800743729553, w2=0.7405911798474785, Bias: -1.103286132808397, Loss: 0.5954163975966363\n",
            "Epochs: 24, Weights: w1=1.064047529900247, w2=0.7487498661214734, Bias: -1.1162681490293287, Loss: 0.5945399677635401\n",
            "Epochs: 25, Weights: w1=1.0781893879527307, w2=0.7568633253859268, Bias: -1.1289428221561595, Loss: 0.5936773013375628\n",
            "Epochs: 26, Weights: w1=1.0923915413924794, w2=0.7649102262037935, Bias: -1.1413474632542204, Loss: 0.5928274773768574\n",
            "Epochs: 27, Weights: w1=1.10664245635512, w2=0.772873951769245, Bias: -1.1535126732830034, Loss: 0.5919897678509144\n",
            "Epochs: 28, Weights: w1=1.1209326832449045, w2=0.7807416859860115, Bias: -1.1654636175336854, Loss: 0.5911635762963106\n",
            "Epochs: 29, Weights: w1=1.1352544614367237, w2=0.7885036744690482, Bias: -1.1772210555624727, Loss: 0.5903483974135045\n",
            "Epochs: 30, Weights: w1=1.149601399646366, w2=0.7961526269703553, Bias: -1.1888021737836476, Loss: 0.5895437903821018\n",
            "Epochs: 31, Weights: w1=1.1639682174190504, w2=0.8036832341595136, Bias: -1.200221258734975, Loss: 0.5887493611686861\n",
            "Epochs: 32, Weights: w1=1.1783505359966953, w2=0.8110917768830211, Bias: -1.2114902416654485, Loss: 0.5879647507337892\n",
            "Epochs: 33, Weights: w1=1.1927447090890875, w2=0.8183758102212125, Bias: -1.222619139168678, Loss: 0.5871896271123954\n",
            "Epochs: 34, Weights: w1=1.2071476858996806, w2=0.8255339080497164, Bias: -1.2336164098120037, Loss: 0.5864236800410902\n",
            "Epochs: 35, Weights: w1=1.2215569002288702, w2=0.8325654565494686, Bias: -1.2444892428652716, Loss: 0.5856666172623348\n",
            "Epochs: 36, Weights: w1=1.2359701806651067, w2=0.8394704873207285, Bias: -1.2552437921326303, Loss: 0.5849181619358202\n",
            "Epochs: 37, Weights: w1=1.2503856778324478, w2=0.8462495425435972, Bias: -1.2658853653901176, Loss: 0.5841780507830016\n",
            "Epochs: 38, Weights: w1=1.2648018054366343, w2=0.8529035660719022, Bias: -1.2764185779143389, Loss: 0.5834460327194276\n",
            "Epochs: 39, Weights: w1=1.2792171924762794, w2=0.8594338155149117, Bias: -1.2868474769592795, Loss: 0.5827218678136976\n",
            "Epochs: 40, Weights: w1=1.2936306444901333, w2=0.8658417913053666, Bias: -1.2971756427237582, Loss: 0.5820053264670804\n",
            "Epochs: 41, Weights: w1=1.3080411121188162, w2=0.8721291795157031, Bias: -1.307406270290465, Loss: 0.5812961887440372\n",
            "Epochs: 42, Weights: w1=1.322447665588614, w2=0.8782978058017471, Bias: -1.3175422361600275, Loss: 0.5805942438076307\n",
            "Epochs: 43, Weights: w1=1.3368494739909818, w2=0.884349598352587, Bias: -1.3275861523107328, Loss: 0.5798992894293717\n",
            "Epochs: 44, Weights: w1=1.351245788446452, w2=0.8902865581293742, Bias: -1.33754041015463, Loss: 0.5792111315532983\n",
            "Epochs: 45, Weights: w1=1.365635928415506, w2=0.8961107350027305, Bias: -1.3474072163081734, Loss: 0.5785295839007779\n",
            "Epochs: 46, Weights: w1=1.3800192705595609, w2=0.9018242086630098, Bias: -1.3571886217296762, Loss: 0.5778544676069541\n",
            "Epochs: 47, Weights: w1=1.394395239668924, w2=0.9074290733917928, Bias: -1.3668865454799815, Loss: 0.5771856108826511\n",
            "Epochs: 48, Weights: w1=1.4087633012665448, w2=0.9129274259563326, Bias: -1.3765027941234664, Loss: 0.5765228486974677\n",
            "Epochs: 49, Weights: w1=1.423122955570802, w2=0.9183213560289964, Bias: -1.386039077592939, Loss: 0.5758660224810618\n",
            "Epochs: 50, Weights: w1=1.4374737325607774, w2=0.9236129386473747, Bias: -1.3954970221853789, Loss: 0.57521497984045\n",
            "Epochs: 51, Weights: w1=1.451815187936195, w2=0.9288042283227415, Bias: -1.4048781812287556, Loss: 0.5745695742917208\n",
            "Epochs: 52, Weights: w1=1.466146899803645, w2=0.9338972544790727, Bias: -1.4141840438575968, Loss: 0.5739296650049233\n",
            "Epochs: 53, Weights: w1=1.480468465952649, w2=0.9388940179651897, Bias: -1.4234160422519593, Loss: 0.5732951165611466\n",
            "Epochs: 54, Weights: w1=1.4947795016109677, w2=0.9437964884314968, Bias: -1.4325755576272503, Loss: 0.572665798720987\n",
            "Epochs: 55, Weights: w1=1.5090796375895024, w2=0.948606602402398, Bias: -1.4416639252079155, Loss: 0.5720415862037088\n",
            "Epochs: 56, Weights: w1=1.5233685187440862, w2=0.953326261907583, Bias: -1.4506824383739403, Loss: 0.5714223584765049\n",
            "Epochs: 57, Weights: w1=1.5376458026952102, w2=0.9579573335613822, Bias: -1.459632352133409, Loss: 0.5708079995533145\n",
            "Epochs: 58, Weights: w1=1.5519111587578533, w2=0.9625016480004798, Bias: -1.46851488604544, Loss: 0.5701983978027128\n",
            "Epochs: 59, Weights: w1=1.566164267042607, w2=0.9669609996073564, Bias: -1.4773312266943863, Loss: 0.5695934457644202\n",
            "Epochs: 60, Weights: w1=1.5804048176965948, w2=0.9713371464606892, Bias: -1.4860825297971891, Loss: 0.5689930399740125\n",
            "Epochs: 61, Weights: w1=1.5946325102586145, w2=0.9756318104651635, Bias: -1.494769922010387, Loss: 0.5683970807954402\n",
            "Epochs: 62, Weights: w1=1.6088470531077341, w2=0.9798466776222514, Bias: -1.5033945024907955, Loss: 0.567805472260982\n",
            "Epochs: 63, Weights: w1=1.6230481629884672, w2=0.9839833984108991, Bias: -1.5119573442537566, Loss: 0.5672181219182891\n",
            "Epochs: 64, Weights: w1=1.6372355645988161, w2=0.9880435882530367, Bias: -1.5204594953646458, Loss: 0.5666349406841831\n",
            "Epochs: 65, Weights: w1=1.651408990230033, w2=0.9920288280436869, Bias: -1.528901979992673, Loss: 0.5660558427048948\n",
            "Epochs: 66, Weights: w1=1.6655681794490296, w2=0.9959406647293703, Bias: -1.537285799350605, Loss: 0.5654807452224467\n",
            "Epochs: 67, Weights: w1=1.679712878816051, w2=0.9997806119217009, Bias: -1.5456119325396578, Loss: 0.5649095684468904\n",
            "Epochs: 68, Weights: w1=1.6938428416316054, w2=1.0035501505356428, Bias: -1.5538813373152485, Loss: 0.5643422354341351\n",
            "Epochs: 69, Weights: w1=1.7079578277077483, w2=1.0072507294439959, Bias: -1.562094950786406, Loss: 0.5637786719691038\n",
            "Epochs: 70, Weights: w1=1.7220576031597232, w2=1.0108837661413745, Bias: -1.5702536900592934, Loss: 0.5632188064539767\n",
            "Epochs: 71, Weights: w1=1.7361419402147003, w2=1.0144506474123152, Bias: -1.5783584528333914, Loss: 0.5626625698012876\n",
            "Epochs: 72, Weights: w1=1.7502106170349419, w2=1.017952729999263, Bias: -1.5864101179573382, Loss: 0.56210989533165\n",
            "Epochs: 73, Weights: w1=1.7642634175532188, w2=1.0213913412670874, Bias: -1.594409545950168, Loss: 0.5615607186759047\n",
            "Epochs: 74, Weights: w1=1.7783001313186844, w2=1.024767779861504, Bias: -1.6023575794926601, Loss: 0.5610149776814854\n",
            "Epochs: 75, Weights: w1=1.792320553351743, w2=1.0280833163593683, Bias: -1.6102550438926826, Loss: 0.5604726123228126\n",
            "Epochs: 76, Weights: w1=1.806324484006705, w2=1.031339193909284, Bias: -1.6181027475277316, Loss: 0.5599335646155315\n",
            "Epochs: 77, Weights: w1=1.8203117288412336, w2=1.0345366288613462, Bias: -1.6259014822673188, Loss: 0.5593977785344226\n",
            "Epochs: 78, Weights: w1=1.8342820984917647, w2=1.0376768113851575, Bias: -1.6336520238774053, Loss: 0.5588651999348194\n",
            "Epochs: 79, Weights: w1=1.848235408554217, w2=1.0407609060754912, Bias: -1.6413551324087174, Loss: 0.5583357764773701\n",
            "Epochs: 80, Weights: w1=1.862171479469429, w2=1.0437900525451846, Bias: -1.6490115525704763, Loss: 0.557809457556004\n",
            "Epochs: 81, Weights: w1=1.8760901364128506, w2=1.0467653660050003, Bias: -1.6566220140908279, Loss: 0.5572861942289479\n",
            "Epochs: 82, Weights: w1=1.8899912091880946, w2=1.0496879378303186, Bias: -1.6641872320650648, Loss: 0.5567659391526651\n",
            "Epochs: 83, Weights: w1=1.9038745321240165, w2=1.0525588361146283, Bias: -1.6717079072925594, Loss: 0.5562486465185805\n",
            "Epochs: 84, Weights: w1=1.9177399439750413, w2=1.0553791062098603, Bias: -1.6791847266032005, Loss: 0.5557342719924739\n",
            "Epochs: 85, Weights: w1=1.931587287824499, w2=1.058149771253671, Bias: -1.6866183631740097, Loss: 0.5552227726564174\n",
            "Epochs: 86, Weights: w1=1.9454164109907643, w2=1.0608718326838313, Bias: -1.6940094768365248, Loss: 0.5547141069531505\n",
            "Epochs: 87, Weights: w1=1.9592271649360251, w2=1.0635462707399166, Bias: -1.7013587143754634, Loss: 0.5542082346327791\n",
            "Epochs: 88, Weights: w1=1.9730194051775272, w2=1.0661740449525143, Bias: -1.7086667098191135, Loss: 0.5537051167017024\n",
            "Epochs: 89, Weights: w1=1.986792991201162, w2=1.0687560946201964, Bias: -1.7159340847218538, Loss: 0.5532047153736661\n",
            "Epochs: 90, Weights: w1=2.000547786377281, w2=1.0712933392745105, Bias: -1.7231614484391526, Loss: 0.5527069940228476\n",
            "Epochs: 91, Weights: w1=2.014283657878634, w2=1.07378667913326, Bias: -1.730349398395371, Loss: 0.5522119171388916\n",
            "Epochs: 92, Weights: w1=2.0280004766003334, w2=1.076236995542345, Bias: -1.7374985203446536, Loss: 0.5517194502838009\n",
            "Epochs: 93, Weights: w1=2.0416981170817703, w2=1.078645151406444, Bias: -1.744609388625174, Loss: 0.551229560050611\n",
            "Epochs: 94, Weights: w1=2.0553764574303988, w2=1.0810119916088148, Bias: -1.7516825664069762, Loss: 0.5507422140237653\n",
            "Epochs: 95, Weights: w1=2.0690353792473237, w2=1.0833383434204935, Bias: -1.7587186059336344, Loss: 0.5502573807411205\n",
            "Epochs: 96, Weights: w1=2.0826747675546278, w2=1.085625016899167, Bias: -1.7657180487579405, Loss: 0.5497750296575105\n",
            "Epochs: 97, Weights: w1=2.0962945107243782, w2=1.0878728052779936, Bias: -1.7726814259718129, Loss: 0.549295131109801\n",
            "Epochs: 98, Weights: w1=2.109894500409261, w2=1.090082485344639, Bias: -1.7796092584306096, Loss: 0.548817656283374\n",
            "Epochs: 99, Weights: w1=2.1234746314747883, w2=1.0922548178107931, Bias: -1.7865020569720171, Loss: 0.5483425771799767\n",
            "Final Weights: w1=2.1234746314747883, w2=1.0922548178107931, Bias: -1.7865020569720171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scratch_network.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3OR_ObIrNBS",
        "outputId": "87b469cd-8dcc-4609-cba5-9b1a87e02a87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9     0.645902\n",
              "8     0.650743\n",
              "5     0.621260\n",
              "0     0.443472\n",
              "14    0.585709\n",
              "4     0.570172\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}